{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c70ee920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8dd6aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c091d4d8",
   "metadata": {},
   "source": [
    "After importing our requirements, we'll ingest the competition's training and test data into dataframes. Then, we'll convert necessary columns in our training dataframe to lists for processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39e221c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training and test data provided by competition\n",
    "training_data = pd.read_csv('learning-agency-lab-automated-essay-scoring-2/train.csv')\n",
    "testing_data = pd.read_csv('learning-agency-lab-automated-essay-scoring-2/test.csv')\n",
    "\n",
    "essay = training_data['full_text'].tolist()\n",
    "score = training_data['score'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb24858",
   "metadata": {},
   "source": [
    "Here, we'll load spacy's \"large\" pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4015df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load en_core_web_lg spacy pipeline\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7603c71f",
   "metadata": {},
   "source": [
    "Let's create an empty list to hold our **doc** objects. Then, we're going to iterate through every essay and score in our training data, and for each, we'll assign truth values to the doc's cats attribute. We'll use the zip() method to pass (essay, score) tuples through nlp.pipe, which only accepts strings or tuples. \n",
    "\n",
    "This cell may take time to process - remember, we're passing 24,000 full essays through the **doc** pipe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c837c9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for doc, score in nlp.pipe(zip(essay, score), as_tuples=True):\n",
    "    if score == 1:\n",
    "        doc.cats['1'] = 1.0\n",
    "        doc.cats['2'] = 0.0\n",
    "        doc.cats['3'] = 0.0\n",
    "        doc.cats['4'] = 0.0\n",
    "        doc.cats['5'] = 0.0\n",
    "        doc.cats['6'] = 0.0\n",
    "    if score == 2:\n",
    "        doc.cats['1'] = 0.0\n",
    "        doc.cats['2'] = 1.0\n",
    "        doc.cats['3'] = 0.0\n",
    "        doc.cats['4'] = 0.0\n",
    "        doc.cats['5'] = 0.0\n",
    "        doc.cats['6'] = 0.0\n",
    "    if score == 3:\n",
    "        doc.cats['1'] = 0.0\n",
    "        doc.cats['2'] = 0.0\n",
    "        doc.cats['3'] = 1.0\n",
    "        doc.cats['4'] = 0.0\n",
    "        doc.cats['5'] = 0.0\n",
    "        doc.cats['6'] = 0.0\n",
    "    if score == 4:\n",
    "        doc.cats['1'] = 0.0\n",
    "        doc.cats['2'] = 0.0\n",
    "        doc.cats['3'] = 0.0\n",
    "        doc.cats['4'] = 1.0\n",
    "        doc.cats['5'] = 0.0\n",
    "        doc.cats['6'] = 0.0\n",
    "    if score == 5:\n",
    "        doc.cats['1'] = 0.0\n",
    "        doc.cats['2'] = 0.0\n",
    "        doc.cats['3'] = 0.0\n",
    "        doc.cats['4'] = 0.0\n",
    "        doc.cats['5'] = 1.0\n",
    "        doc.cats['6'] = 0.0\n",
    "    if score == 6:\n",
    "        doc.cats['1'] = 0.0\n",
    "        doc.cats['2'] = 0.0\n",
    "        doc.cats['3'] = 0.0\n",
    "        doc.cats['4'] = 0.0\n",
    "        doc.cats['5'] = 0.0\n",
    "        doc.cats['6'] = 1.0\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9914462",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(docs)\n",
    "split = len(docs) * 90 // (90+10)\n",
    "traindocs = docs[:split]\n",
    "evaldocs = docs[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13d8b5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docbin = DocBin(docs=traindocs)\n",
    "eval_docbin = DocBin(docs=evaldocs)\n",
    "train_docbin.to_disk('./train.spacy')\n",
    "eval_docbin.to_disk('./eval.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bf1b490",
   "metadata": {},
   "outputs": [],
   "source": [
    "textcat = nlp.add_pipe('textcat')\n",
    "optimizer = textcat.create_optimizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
